{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the CNN (Convolutional Neural Network).\n",
    "classifier = Sequential()\n",
    "# Convolution - extracting appropriate features from the input image.\n",
    "# Non-Linearity (RELU) - replacing all negative pixel values in feature map by zero.\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3),\n",
    "               activation='relu'))\n",
    "# Pooling: reduces dimensionality of the feature maps but keeps the most important information.\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Adding a second convolutional layer and flattening in order to arrange 3D volumes into a 1D vector.\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Flatten())\n",
    "# Fully connected layers: ensures connections to all activations in the previous layer.\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3642 images belonging to 2 classes.\n",
      "Found 408 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "30/30 [==============================] - 9s 294ms/step - loss: 0.0889 - accuracy: 0.9750 - val_loss: 0.0929 - val_accuracy: 0.9809\n",
      "Epoch 2/30\n",
      "30/30 [==============================] - 8s 282ms/step - loss: 0.0269 - accuracy: 0.9944 - val_loss: 0.0683 - val_accuracy: 0.9883\n",
      "Epoch 3/30\n",
      "30/30 [==============================] - 9s 284ms/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 0.0857 - val_accuracy: 0.9831\n",
      "Epoch 4/30\n",
      "30/30 [==============================] - 9s 289ms/step - loss: 0.0354 - accuracy: 0.9889 - val_loss: 0.0838 - val_accuracy: 0.9788\n",
      "Epoch 5/30\n",
      "30/30 [==============================] - 9s 303ms/step - loss: 0.0125 - accuracy: 0.9944 - val_loss: 0.0840 - val_accuracy: 0.9799\n",
      "Epoch 6/30\n",
      "30/30 [==============================] - 9s 286ms/step - loss: 0.0338 - accuracy: 0.9917 - val_loss: 0.0667 - val_accuracy: 0.9852\n",
      "Epoch 7/30\n",
      "30/30 [==============================] - 9s 288ms/step - loss: 0.0237 - accuracy: 0.9944 - val_loss: 0.0610 - val_accuracy: 0.9809\n",
      "Epoch 8/30\n",
      "30/30 [==============================] - 9s 290ms/step - loss: 0.0353 - accuracy: 0.9889 - val_loss: 0.0787 - val_accuracy: 0.9831\n",
      "Epoch 9/30\n",
      "30/30 [==============================] - 9s 293ms/step - loss: 0.0376 - accuracy: 0.9889 - val_loss: 0.0585 - val_accuracy: 0.9883\n",
      "Epoch 10/30\n",
      "30/30 [==============================] - 8s 283ms/step - loss: 0.0531 - accuracy: 0.9861 - val_loss: 0.0665 - val_accuracy: 0.9788\n",
      "Epoch 11/30\n",
      "30/30 [==============================] - 9s 293ms/step - loss: 0.0430 - accuracy: 0.9806 - val_loss: 0.0843 - val_accuracy: 0.9809\n",
      "Epoch 12/30\n",
      "30/30 [==============================] - 9s 289ms/step - loss: 0.0152 - accuracy: 0.9944 - val_loss: 0.0845 - val_accuracy: 0.9841\n",
      "Epoch 13/30\n",
      "30/30 [==============================] - 9s 284ms/step - loss: 0.0386 - accuracy: 0.9861 - val_loss: 0.0705 - val_accuracy: 0.9852\n",
      "Epoch 14/30\n",
      "30/30 [==============================] - 9s 302ms/step - loss: 0.0224 - accuracy: 0.9972 - val_loss: 0.0894 - val_accuracy: 0.9873\n",
      "Epoch 15/30\n",
      "30/30 [==============================] - 8s 283ms/step - loss: 0.0376 - accuracy: 0.9889 - val_loss: 0.0799 - val_accuracy: 0.9852\n",
      "Epoch 16/30\n",
      "30/30 [==============================] - 9s 294ms/step - loss: 0.0243 - accuracy: 0.9972 - val_loss: 0.0666 - val_accuracy: 0.9831\n",
      "Epoch 17/30\n",
      "30/30 [==============================] - 9s 298ms/step - loss: 0.0203 - accuracy: 0.9944 - val_loss: 0.0703 - val_accuracy: 0.9831\n",
      "Epoch 18/30\n",
      "30/30 [==============================] - 9s 283ms/step - loss: 0.0478 - accuracy: 0.9833 - val_loss: 0.1149 - val_accuracy: 0.9735\n",
      "Epoch 19/30\n",
      "30/30 [==============================] - 9s 298ms/step - loss: 0.0588 - accuracy: 0.9750 - val_loss: 0.0650 - val_accuracy: 0.9883\n",
      "Epoch 20/30\n",
      "30/30 [==============================] - 9s 308ms/step - loss: 0.0191 - accuracy: 0.9917 - val_loss: 0.0767 - val_accuracy: 0.9883\n",
      "Epoch 21/30\n",
      "30/30 [==============================] - 10s 317ms/step - loss: 0.0171 - accuracy: 0.9972 - val_loss: 0.1018 - val_accuracy: 0.9778\n",
      "Epoch 22/30\n",
      "30/30 [==============================] - 9s 298ms/step - loss: 0.0442 - accuracy: 0.9889 - val_loss: 0.0852 - val_accuracy: 0.9820\n",
      "Epoch 23/30\n",
      "30/30 [==============================] - 8s 277ms/step - loss: 0.0583 - accuracy: 0.9806 - val_loss: 0.0836 - val_accuracy: 0.9862\n",
      "Epoch 24/30\n",
      "30/30 [==============================] - 8s 279ms/step - loss: 0.0365 - accuracy: 0.9889 - val_loss: 0.0677 - val_accuracy: 0.9820\n",
      "Epoch 25/30\n",
      "30/30 [==============================] - 8s 281ms/step - loss: 0.0411 - accuracy: 0.9917 - val_loss: 0.0881 - val_accuracy: 0.9831\n",
      "Epoch 26/30\n",
      "30/30 [==============================] - 9s 284ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 0.9799\n",
      "Epoch 27/30\n",
      "30/30 [==============================] - 9s 296ms/step - loss: 0.0398 - accuracy: 0.9889 - val_loss: 0.0930 - val_accuracy: 0.9682\n",
      "Epoch 28/30\n",
      "30/30 [==============================] - 8s 281ms/step - loss: 0.0530 - accuracy: 0.9833 - val_loss: 0.0782 - val_accuracy: 0.9841\n",
      "Epoch 29/30\n",
      "30/30 [==============================] - 8s 282ms/step - loss: 0.0383 - accuracy: 0.9833 - val_loss: 0.0868 - val_accuracy: 0.9820\n",
      "Epoch 30/30\n",
      "30/30 [==============================] - 8s 278ms/step - loss: 0.0139 - accuracy: 0.9972 - val_loss: 0.0801 - val_accuracy: 0.9831\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "#tensorboard stuff\n",
    "#logdir = \"./FolderFrames/logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "\n",
    "# Compile the CNN and train the classifier..\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "train_imagedata = ImageDataGenerator(rescale=1. / 255, shear_range=0.2,\n",
    "        zoom_range=0.2, horizontal_flip=True)\n",
    "test_imagedata = ImageDataGenerator(rescale=1. / 255)\n",
    "training_set = \\\n",
    "    train_imagedata.flow_from_directory('./FolderFrames/MrsPiggyDataset/MrsPiggyTrainingSet'\n",
    "        , target_size=(64, 64), batch_size=12, class_mode='binary')\n",
    "val_set = \\\n",
    "    test_imagedata.flow_from_directory('./FolderFrames/MrsPiggyDataset/MrsPiggyValSet'\n",
    "        , target_size=(64, 64), batch_size=32, class_mode='binary')\n",
    "history=classifier.fit_generator(training_set, steps_per_epoch=30, epochs=30,\n",
    "                         validation_data=val_set,\n",
    "                         validation_steps=30, callbacks=[tf.keras.callbacks.TensorBoard()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 813,217\n",
      "Trainable params: 813,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = classifier.to_json()\n",
    "with open(\"./FolderFrames/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "classifier.save_weights(\"./FolderFrames/model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#evaluate model\n",
    "from sklearn.metrics import roc_curve\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from PIL import Image\n",
    "import glob\n",
    "import cv2 as cv2\n",
    "\n",
    "test_set = []\n",
    "for filename in glob.glob('./FolderFrames/MrsPiggyDataset/MrsPiggyTestSet/*.jpg'): #assuming gif\n",
    "    im = np.asarray(Image.open(filename))\n",
    "    im = cv2.resize(im, dsize=(64, 64), interpolation=cv2.INTER_CUBIC)\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    test_set.append(im)\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('./FolderFrames/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"./FolderFrames/model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "\n",
    "y_pred_keras = loaded_model.predict(test_set).ravel()\n",
    "#fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
