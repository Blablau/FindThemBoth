{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read\n",
    "import matplotlib.pyplot as plt\n",
    "from os import walk\n",
    "import os\n",
    "\n",
    "features = []\n",
    "pathNoMrsPiggy = './FolderFrames/MrsPiggyAudioTrainingSet/NoMrsPiggy/'\n",
    "pathYesMrsPiggy = './FolderFrames/MrsPiggyAudioTrainingSet/YesMrsPiggy/'\n",
    "\n",
    "for filename in os.listdir(pathYesMrsPiggy):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        # read audio samples\n",
    "        input_data = read(pathYesMrsPiggy + filename)\n",
    "        audio = input_data[1]\n",
    "        # plot the first 1024 samples\n",
    "        plt.plot(audio)\n",
    "        # label the axes\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        # set the title\n",
    "        # plt.title(\"Sample Wav\")\n",
    "        # display the plot\n",
    "        plt.savefig(\"FolderFrames/yesPlots/\" + filename.split(\".\")[0] + '.png')\n",
    "        # plt.show()\n",
    "        plt.close('all')\n",
    "        \n",
    "for filename in os.listdir(pathNoMrsPiggy):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        # read audio samples\n",
    "        input_data = read(pathNoMrsPiggy + filename)\n",
    "        audio = input_data[1]\n",
    "        # plot the first 1024 samples\n",
    "        plt.plot(audio)\n",
    "        # label the axes\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        # set the title\n",
    "        # plt.title(\"Sample Wav\")\n",
    "        # display the plot\n",
    "        plt.savefig(\"FolderFrames/noPlots/\" + filename.split(\".\")[0] + '.png')\n",
    "        # plt.show()\n",
    "        plt.close('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found all yes_plots\n",
      "appended all yes_plots\n",
      "found all no_plots\n",
      "appended all no_plots\n",
      "finished reading plots.\n",
      "generated train/val split.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=0, tol=1e-05,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "base_model = VGG19(weights='imagenet')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('flatten').output)\n",
    "\n",
    "def get_features(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    flatten = model.predict(x)\n",
    "    return list(flatten[0])\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "yes_plots = []\n",
    "for (_,_,filenames) in os.walk('FolderFrames/yesPlots'):\n",
    "    yes_plots.extend(filenames)\n",
    "    break\n",
    "\n",
    "print(\"found all yes_plots\")\n",
    "for yplot in yes_plots:\n",
    "    X.append(get_features('FolderFrames/yesPlots/' + yplot))\n",
    "    y.append(1)\n",
    "print(\"appended all yes_plots\")\n",
    "\n",
    "no_plots = []\n",
    "for (_,_,filenames) in os.walk('FolderFrames/noPlots'):\n",
    "    no_plots.extend(filenames)\n",
    "    break\n",
    "print(\"found all no_plots\")\n",
    "for nplot in no_plots:\n",
    "    X.append(get_features('FolderFrames/noPlots/' + nplot))\n",
    "    y.append(0)\n",
    "print(\"appended all no_plots\")\n",
    "print(\"finished reading plots.\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "\n",
    "print(\"generated train/val split.\")\n",
    "\n",
    "clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"./FolderFrames/DeepPlotMrsPiggyModel/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"./FolderFrames/DeepPlotMrsPiggyModel//model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "(487, 25088)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_7 to have 4 dimensions, but got array with shape (487, 25088)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-d1f1dd911ed0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mX_ti\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_ti\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0my_pred_keras\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_ti\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mfpr_keras\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr_keras\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds_keras\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_keras\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\Anaconda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    906\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 908\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\Anaconda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_or_infer_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m     x, _, _ = model._standardize_user_data(\n\u001b[1;32m--> 716\u001b[1;33m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[0;32m    717\u001b[0m     return predict_loop(\n\u001b[0;32m    718\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\Anaconda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2469\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2470\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2471\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2473\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\Anaconda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    561\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    564\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input_7 to have 4 dimensions, but got array with shape (487, 25088)"
     ]
    }
   ],
   "source": [
    "# Further evaluate (ROC curve)\n",
    "from sklearn.metrics import auc\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('./FolderFrames/DeepPlotMrsPiggyModel/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"./FolderFrames/DeepPlotMrsPiggyModel/model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "y_pred_keras = loaded_model.predict(X_ti).ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred_keras)\n",
    "\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9281314168377823\n"
     ]
    }
   ],
   "source": [
    "predicted = clf.predict(X_test)\n",
    "\n",
    "# get the accuracy\n",
    "print (accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# path to no test data\n",
    "\n",
    "import cv2 as cv2\n",
    "test_path = \"./FolderFrames/testNoPlots\"\n",
    "\n",
    "# loop through the test images\n",
    "#for file in glob.glob(test_path + \"/*.jpg\"):\n",
    "for file in os.listdir(test_path):    \n",
    "\n",
    "    file = test_path + \"/\" + file\n",
    "    \n",
    "    feature = get_features(file)\n",
    "    feature = np.hstack([feature])\n",
    "    # predict label of test image\n",
    "    prediction = clf.predict(feature.reshape(1,-1))\n",
    "\n",
    "    # show predicted label on image\n",
    "    #cv2.putText(image, train_labels[prediction], (20,30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,255,255), 3)\n",
    "\n",
    "    # display the output image\n",
    "    #plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    #plt.show()\n",
    "    if prediction:\n",
    "        print(\"YES Kermit speaking:\")\n",
    "        \n",
    "    else:\n",
    "        print(\"NO Kermit not speaking:\")\n",
    "    #IPython.display.display(IPython.display.Audio(file, rate=250))\n",
    "    print(\"-----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES Kermit speaking:\n",
      "-----------------------------------------------\n",
      "YES Kermit speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "YES Kermit speaking:\n",
      "-----------------------------------------------\n",
      "NO Kermit not speaking:\n",
      "-----------------------------------------------\n",
      "YES Kermit speaking:\n",
      "-----------------------------------------------\n",
      "YES Kermit speaking:\n",
      "-----------------------------------------------\n",
      "YES Kermit speaking:\n",
      "-----------------------------------------------\n",
      "YES Kermit speaking:\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# path to yes test data\n",
    "\n",
    "import cv2 as cv2\n",
    "test_path = \"./FolderFrames/testYesPlots\"\n",
    "\n",
    "# loop through the test images\n",
    "#for file in glob.glob(test_path + \"/*.jpg\"):\n",
    "for file in os.listdir(test_path):    \n",
    "\n",
    "    file = test_path + \"/\" + file\n",
    "    \n",
    "    feature = get_features(file)\n",
    "    feature = np.hstack([feature])\n",
    "    # predict label of test image\n",
    "    prediction = clf.predict(feature.reshape(1,-1))\n",
    "\n",
    "    # show predicted label on image\n",
    "    #cv2.putText(image, train_labels[prediction], (20,30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,255,255), 3)\n",
    "\n",
    "    # display the output image\n",
    "    #plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    #plt.show()\n",
    "    if prediction:\n",
    "        print(\"YES Kermit speaking:\")\n",
    "        \n",
    "    else:\n",
    "        print(\"NO Kermit not speaking:\")\n",
    "    #IPython.display.display(IPython.display.Audio(file, rate=250))\n",
    "    print(\"-----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further evaluate (ROC curve)\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('./FolderFrames/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"./FolderFrames/model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "test_set = np.array(test_set)\n",
    "y_pred_keras = loaded_model.predict(test_set).ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(mrsPiggyGT, y_pred_keras)\n",
    "\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
