{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the CNN (Convolutional Neural Network).\n",
    "classifier = Sequential()\n",
    "# Convolution - extracting appropriate features from the input image.\n",
    "# Non-Linearity (RELU) - replacing all negative pixel values in feature map by zero.\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3),\n",
    "               activation='relu'))\n",
    "# Pooling: reduces dimensionality of the feature maps but keeps the most important information.\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Adding a second convolutional layer and flattening in order to arrange 3D volumes into a 1D vector.\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Flatten())\n",
    "# Fully connected layers: ensures connections to all activations in the previous layer.\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3642 images belonging to 2 classes.\n",
      "Found 408 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "30/30 [==============================] - 9s 294ms/step - loss: 0.0889 - accuracy: 0.9750 - val_loss: 0.0929 - val_accuracy: 0.9809\n",
      "Epoch 2/30\n",
      "30/30 [==============================] - 8s 282ms/step - loss: 0.0269 - accuracy: 0.9944 - val_loss: 0.0683 - val_accuracy: 0.9883\n",
      "Epoch 3/30\n",
      "30/30 [==============================] - 9s 284ms/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 0.0857 - val_accuracy: 0.9831\n",
      "Epoch 4/30\n",
      "30/30 [==============================] - 9s 289ms/step - loss: 0.0354 - accuracy: 0.9889 - val_loss: 0.0838 - val_accuracy: 0.9788\n",
      "Epoch 5/30\n",
      "30/30 [==============================] - 9s 303ms/step - loss: 0.0125 - accuracy: 0.9944 - val_loss: 0.0840 - val_accuracy: 0.9799\n",
      "Epoch 6/30\n",
      "30/30 [==============================] - 9s 286ms/step - loss: 0.0338 - accuracy: 0.9917 - val_loss: 0.0667 - val_accuracy: 0.9852\n",
      "Epoch 7/30\n",
      "30/30 [==============================] - 9s 288ms/step - loss: 0.0237 - accuracy: 0.9944 - val_loss: 0.0610 - val_accuracy: 0.9809\n",
      "Epoch 8/30\n",
      "30/30 [==============================] - 9s 290ms/step - loss: 0.0353 - accuracy: 0.9889 - val_loss: 0.0787 - val_accuracy: 0.9831\n",
      "Epoch 9/30\n",
      "30/30 [==============================] - 9s 293ms/step - loss: 0.0376 - accuracy: 0.9889 - val_loss: 0.0585 - val_accuracy: 0.9883\n",
      "Epoch 10/30\n",
      "30/30 [==============================] - 8s 283ms/step - loss: 0.0531 - accuracy: 0.9861 - val_loss: 0.0665 - val_accuracy: 0.9788\n",
      "Epoch 11/30\n",
      "30/30 [==============================] - 9s 293ms/step - loss: 0.0430 - accuracy: 0.9806 - val_loss: 0.0843 - val_accuracy: 0.9809\n",
      "Epoch 12/30\n",
      "30/30 [==============================] - 9s 289ms/step - loss: 0.0152 - accuracy: 0.9944 - val_loss: 0.0845 - val_accuracy: 0.9841\n",
      "Epoch 13/30\n",
      "30/30 [==============================] - 9s 284ms/step - loss: 0.0386 - accuracy: 0.9861 - val_loss: 0.0705 - val_accuracy: 0.9852\n",
      "Epoch 14/30\n",
      "30/30 [==============================] - 9s 302ms/step - loss: 0.0224 - accuracy: 0.9972 - val_loss: 0.0894 - val_accuracy: 0.9873\n",
      "Epoch 15/30\n",
      "30/30 [==============================] - 8s 283ms/step - loss: 0.0376 - accuracy: 0.9889 - val_loss: 0.0799 - val_accuracy: 0.9852\n",
      "Epoch 16/30\n",
      "30/30 [==============================] - 9s 294ms/step - loss: 0.0243 - accuracy: 0.9972 - val_loss: 0.0666 - val_accuracy: 0.9831\n",
      "Epoch 17/30\n",
      "30/30 [==============================] - 9s 298ms/step - loss: 0.0203 - accuracy: 0.9944 - val_loss: 0.0703 - val_accuracy: 0.9831\n",
      "Epoch 18/30\n",
      "30/30 [==============================] - 9s 283ms/step - loss: 0.0478 - accuracy: 0.9833 - val_loss: 0.1149 - val_accuracy: 0.9735\n",
      "Epoch 19/30\n",
      "30/30 [==============================] - 9s 298ms/step - loss: 0.0588 - accuracy: 0.9750 - val_loss: 0.0650 - val_accuracy: 0.9883\n",
      "Epoch 20/30\n",
      "30/30 [==============================] - 9s 308ms/step - loss: 0.0191 - accuracy: 0.9917 - val_loss: 0.0767 - val_accuracy: 0.9883\n",
      "Epoch 21/30\n",
      "30/30 [==============================] - 10s 317ms/step - loss: 0.0171 - accuracy: 0.9972 - val_loss: 0.1018 - val_accuracy: 0.9778\n",
      "Epoch 22/30\n",
      "30/30 [==============================] - 9s 298ms/step - loss: 0.0442 - accuracy: 0.9889 - val_loss: 0.0852 - val_accuracy: 0.9820\n",
      "Epoch 23/30\n",
      "30/30 [==============================] - 8s 277ms/step - loss: 0.0583 - accuracy: 0.9806 - val_loss: 0.0836 - val_accuracy: 0.9862\n",
      "Epoch 24/30\n",
      "30/30 [==============================] - 8s 279ms/step - loss: 0.0365 - accuracy: 0.9889 - val_loss: 0.0677 - val_accuracy: 0.9820\n",
      "Epoch 25/30\n",
      "30/30 [==============================] - 8s 281ms/step - loss: 0.0411 - accuracy: 0.9917 - val_loss: 0.0881 - val_accuracy: 0.9831\n",
      "Epoch 26/30\n",
      "30/30 [==============================] - 9s 284ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 0.9799\n",
      "Epoch 27/30\n",
      "30/30 [==============================] - 9s 296ms/step - loss: 0.0398 - accuracy: 0.9889 - val_loss: 0.0930 - val_accuracy: 0.9682\n",
      "Epoch 28/30\n",
      "30/30 [==============================] - 8s 281ms/step - loss: 0.0530 - accuracy: 0.9833 - val_loss: 0.0782 - val_accuracy: 0.9841\n",
      "Epoch 29/30\n",
      "30/30 [==============================] - 8s 282ms/step - loss: 0.0383 - accuracy: 0.9833 - val_loss: 0.0868 - val_accuracy: 0.9820\n",
      "Epoch 30/30\n",
      "30/30 [==============================] - 8s 278ms/step - loss: 0.0139 - accuracy: 0.9972 - val_loss: 0.0801 - val_accuracy: 0.9831\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "#tensorboard stuff\n",
    "#logdir = \"./FolderFrames/logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "\n",
    "# Compile the CNN and train the classifier..\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "train_imagedata = ImageDataGenerator(rescale=1. / 255, shear_range=0.2,\n",
    "        zoom_range=0.2, horizontal_flip=True)\n",
    "test_imagedata = ImageDataGenerator(rescale=1. / 255)\n",
    "training_set = \\\n",
    "    train_imagedata.flow_from_directory('./FolderFrames/MrsPiggyDataset/MrsPiggyTrainingSet'\n",
    "        , target_size=(64, 64), batch_size=12, class_mode='binary')\n",
    "val_set = \\\n",
    "    test_imagedata.flow_from_directory('./FolderFrames/MrsPiggyDataset/MrsPiggyValSet'\n",
    "        , target_size=(64, 64), batch_size=32, class_mode='binary')\n",
    "history=classifier.fit_generator(training_set, steps_per_epoch=30, epochs=30,\n",
    "                         validation_data=val_set,\n",
    "                         validation_steps=30, callbacks=[tf.keras.callbacks.TensorBoard()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 813,217\n",
      "Trainable params: 813,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = classifier.to_json()\n",
    "with open(\"./FolderFrames/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "classifier.save_weights(\"./FolderFrames/model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_input to have 4 dimensions, but got array with shape (544, 720, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-2f549d353dbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0my_pred_keras\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;31m#fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred_keras)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\Anaconda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\Anaconda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    713\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_or_infer_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m     x, _, _ = model._standardize_user_data(\n\u001b[1;32m--> 715\u001b[1;33m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[0;32m    716\u001b[0m     return predict_loop(\n\u001b[0;32m    717\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\Anaconda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2472\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\Anaconda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    563\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 565\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    566\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_input to have 4 dimensions, but got array with shape (544, 720, 3)"
     ]
    }
   ],
   "source": [
    "#evaluate model\n",
    "from sklearn.metrics import roc_curve\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "test_set = []\n",
    "for filename in glob.glob('./FolderFrames/MrsPiggyDataset/MrsPiggyTestSet/*.jpg'): #assuming gif\n",
    "    im = np.asarray(Image.open(filename))\n",
    "    im.reshape((-1, im.shape[0], im.shape[1], im.shape[3]))\n",
    "    test_set.append(im)\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('./FolderFrames/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"./FolderFrames/model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "\n",
    "y_pred_keras = loaded_model.predict(test_set).ravel()\n",
    "#fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
